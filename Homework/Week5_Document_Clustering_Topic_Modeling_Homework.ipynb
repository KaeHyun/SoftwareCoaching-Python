{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week5_Document_Clustering_Topic_Modeling_Homework.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"N20cQ6qpnwrU"},"source":["# Software Coaching for Python\n","# Week 5: Document Clustering & Topic Modeling - Homework"]},{"cell_type":"markdown","metadata":{"id":"2wg-EeHjnwrZ"},"source":["Instructor: Kang-Pyo Lee"]},{"cell_type":"code","metadata":{"id":"Le_Xkfczn7yk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637396787944,"user_tz":-540,"elapsed":301,"user":{"displayName":"엄계현","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14311331572526917358"}},"outputId":"4c1735e8-9593-416a-ba2b-b9af28755ac2"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","path = \"/content/gdrive/Shareddrives/Software_Coaching_Fall_2021\"\n","my_folder = \"KPL\"     # *** REPLACE WITH YOUR FOLDER NAME ***\n","outcome_folder = f\"{path}/{my_folder}/outcome\"\n","classdata_folder = f\"{path}/classdata\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"uKBQR7A4f2Bf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b479bd33-3d10-439a-9449-7fef245ce90b"},"source":["! pip install --user scikit-learn pyldavis"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Requirement already satisfied: pyldavis in /root/.local/lib/python3.7/site-packages (3.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /root/.local/lib/python3.7/site-packages (from scikit-learn) (1.21.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.11.3)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyldavis) (3.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.16.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.0)\n","Requirement already satisfied: pandas>=1.2.0 in /root/.local/lib/python3.7/site-packages (from pyldavis) (1.3.4)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.7.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyldavis) (57.4.0)\n","Requirement already satisfied: funcy in /root/.local/lib/python3.7/site-packages (from pyldavis) (1.16)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyldavis) (5.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyldavis) (2.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"3mMmFjHgoGO7"},"source":["import pandas as pd\n","pd.set_option('display.max_colwidth', 150)\n","\n","df = pd.read_csv(f\"{classdata_folder}/timeline_NASA.csv\", sep=\"\\t\")\n","df.text = df.text.astype(str)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aibpa79LdVmP"},"source":["Check if there are any duplicates in the `text` column."]},{"cell_type":"code","metadata":{"id":"W-ii40T3dVmP"},"source":["df.text.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NKrcIDtWdVmQ"},"source":["Remove duplicates in the `text` column, if any. "]},{"cell_type":"code","metadata":{"id":"u2ZekSkPdVmQ"},"source":["df = df.drop_duplicates([\"text\"], keep=\"first\").copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYgopVokdVmQ"},"source":["df.text.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jfstQyVfdVmQ"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOqEMJ_QdVmR"},"source":["## Preparing Data for Modeling"]},{"cell_type":"code","metadata":{"id":"4kAgIh5udVmR"},"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download(['punkt', 'averaged_perceptron_tagger', 'stopwords'])\n","\n","import string \n","global_stopwords = stopwords.words(\"english\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1K1AlL2xdVmR"},"source":["Define your own local stopwords. "]},{"cell_type":"code","metadata":{"id":"Ymwh-xs-dVmR"},"source":["local_stopwords = [c for c in string.punctuation] +\\\n","                  ['‘', '’', '—', '…', '“', '”', \"'re\", \"'s\", '...', 'a…', 't…', 'https', \"n't\", 'rt']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DZU40zVdVmS"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=global_stopwords+local_stopwords, max_df=0.7)\n","X = vectorizer.fit_transform(df.text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_3EDpm-qdVmS"},"source":["X.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ZCu8jNcdVmS"},"source":["## K-Means Clustering"]},{"cell_type":"markdown","metadata":{"id":"IuuzG6vtdVmS"},"source":["### Step 1. Choose the number of clusters"]},{"cell_type":"markdown","metadata":{"id":"IXF-l5m5dVmS"},"source":["Set the number of clusters you would like to get. "]},{"cell_type":"code","metadata":{"id":"xMHAw4jvdVmT"},"source":["# Your answer here\n","k = 5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJD3TDBIdVmT"},"source":["### Step 2. Initialize a model object for k-means clustering"]},{"cell_type":"code","metadata":{"id":"Zfq9QWeXdVmT"},"source":["from sklearn.cluster import KMeans\n","\n","kmeans = KMeans(n_clusters=k, random_state=0)\n","kmeans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Au2R5fJdVmT"},"source":["### Step 3. Fit the model using the input data"]},{"cell_type":"code","metadata":{"id":"R_nhbbh-dVmT"},"source":["%time kmeans.fit(X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMleEQSudVmT"},"source":["### Step 4. Examine the clustering outcome"]},{"cell_type":"code","metadata":{"id":"QkoDd3HwdVmU"},"source":["kmeans.labels_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDWSEZFNdVmU"},"source":["df[\"cluster\"] = kmeans.labels_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rNUyb6hJdVmU"},"source":["df[[\"text\", \"cluster\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tso-LPoEdVmU"},"source":["Check the number of values for each cluster. "]},{"cell_type":"code","metadata":{"id":"63M5PKDqdVmU"},"source":["df.cluster.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k9jpG-FzdVmU"},"source":["Check 10 random texts from the largest cluster. "]},{"cell_type":"code","metadata":{"id":"T1jy3v3XdVmV"},"source":["df[df.cluster == 1].sample(10, random_state=0)[[\"text\", \"cluster\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4gq2AkvdVmV"},"source":["Check 10 random texts from the second largest cluster. "]},{"cell_type":"code","metadata":{"id":"rEq-lw7vdVmV"},"source":["df[df.cluster == 2].sample(10, random_state=0)[[\"text\", \"cluster\"]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7n1DVx_ydVmV"},"source":["import nltk\n","df[\"words\"] = df.text.apply(lambda x: nltk.word_tokenize(x))\n","df[\"tagged_words\"] = df.words.apply(lambda x: nltk.pos_tag(x))\n","\n","from collections import Counter\n","\n","def get_counter(dataframe, stopwords=[]):\n","    counter = Counter()\n","    \n","    for l in dataframe.tagged_words:\n","        word_set = set()\n","\n","        for t in l:\n","            word = t[0].lower()\n","            tag = t[1]\n","\n","            if word not in stopwords:\n","                word_set.add(word)\n","            \n","        counter.update(word_set)\n","        \n","    return counter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cd3eutxYdVmW"},"source":["Check the top-30 most common keywords in the largest cluster. (Replace the cluster number as needed.)"]},{"cell_type":"code","metadata":{"id":"296wEep5dVmW"},"source":["counter0 = get_counter(df[df.cluster == 1], global_stopwords+local_stopwords)\n","counter0.most_common(30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NvaG6sqDdVmW"},"source":["Check the top-30 most common keywords in the second largest cluster. (Replace the cluster number as needed.)"]},{"cell_type":"code","metadata":{"id":"rz8yBu25dVmW"},"source":["counter4 = get_counter(df[df.cluster == 2], global_stopwords+local_stopwords)\n","counter4.most_common(30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oMNUakx8dVmX"},"source":["## LDA Topic Modeling"]},{"cell_type":"markdown","metadata":{"id":"a1Xxz8VhdVmX"},"source":["### Step 1. Choose the number of topics"]},{"cell_type":"markdown","metadata":{"id":"k-i9koYcdVmX"},"source":["Set the number of topics you would like to get. "]},{"cell_type":"code","metadata":{"id":"wxe6AttKdVmX"},"source":["# Your answer here\n","num_topics = 5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DmgqWIBNdVmX"},"source":["### Step 2. Initialize a model object for LDA topic modeling"]},{"cell_type":"code","metadata":{"id":"pQArs63fdVmY"},"source":["from sklearn.decomposition import LatentDirichletAllocation as LDA\n","\n","lda = LDA(n_components=num_topics, random_state=0)\n","lda"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QoBHhvY2dVmY"},"source":["### Step 3. Fit the model using the input data"]},{"cell_type":"code","metadata":{"id":"vpMpp_tudVmY"},"source":["%time lda.fit(X)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zL89j5j0dVmY"},"source":["### Step 4. Examine the output of topic modeling"]},{"cell_type":"code","metadata":{"id":"XBeU4DFidVmZ"},"source":["def show_topics(model, feature_names, num_top_words):\n","    for topic_idx, topic_scores in enumerate(model.components_):\n","        print(\"***Topic {}:\".format(topic_idx))\n","        print(\" + \".join([\"{:.2f} * {}\".format(topic_scores[i], feature_names[i]) for i in topic_scores.argsort()[::-1][:num_top_words]]))\n","        print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"xv2gtoLrdVmZ"},"source":["show_topics(lda, vectorizer.get_feature_names(), 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n1PwFfRMdVma"},"source":["### Topic Model Visualization"]},{"cell_type":"code","metadata":{"id":"OkOB0rSIdVma"},"source":["import pyLDAvis\n","import pyLDAvis.sklearn\n","pyLDAvis.enable_notebook()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-MnfnhLdVma"},"source":["pyLDAvis.sklearn.prepare(lda, X, vectorizer)"],"execution_count":null,"outputs":[]}]}